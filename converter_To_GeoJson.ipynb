{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063e7109",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39e987cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv, json\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97fed0e",
   "metadata": {},
   "source": [
    "Import Datasets to convert to geo json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b00e139a",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_rail_stations1 = pd.read_csv(\"LYNX_Blue_Line_Stations.csv\")\n",
    "light_rail_stations2 = pd.read_csv(\"LYNX_Gold_Line_Stops.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318bc5b7",
   "metadata": {},
   "source": [
    "Mergeing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aef8b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "light_rails = pd.concat([light_rail_stations1, light_rail_stations2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b031ad97",
   "metadata": {},
   "source": [
    "Creating Function to Convert Adress Based Locations to Cord Based Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "222b6b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [01:44<00:00,  2.42s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load stations\n",
    "stations = light_rails\n",
    "# Initialize geocoder\n",
    "geolocator = Nominatim(user_agent=\"charlotte_light_rail_analysis\")\n",
    "\n",
    "latitudes = []\n",
    "longitudes = []\n",
    "\n",
    "for _, row in tqdm(stations.iterrows(), total=len(stations)):\n",
    "    address = f\"{row['Address']}, {[\"Charlotte\"]}, {r\"NC\"}\"\n",
    "    try:\n",
    "        location = geolocator.geocode(address)\n",
    "        if location:\n",
    "            latitudes.append(location.latitude)\n",
    "            longitudes.append(location.longitude)\n",
    "        else:\n",
    "            latitudes.append(None)\n",
    "            longitudes.append(None)\n",
    "        time.sleep(1)  # REQUIRED: respect Nominatim rate limits\n",
    "    except:\n",
    "        latitudes.append(None)\n",
    "        longitudes.append(None)\n",
    "\n",
    "stations[\"latitude\"] = latitudes\n",
    "stations[\"longitude\"] = longitudes\n",
    "\n",
    "#stations.to_csv(\"light_rail_stations_with_coords.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2334ffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_geojson(\n",
    "    df,\n",
    "    lat_col=\"latitude\",\n",
    "    lon_col=\"longitude\",\n",
    "    id_col=None\n",
    "):\n",
    "    # Make a safe copy\n",
    "    df = df.copy()\n",
    "\n",
    "    # Ensure numeric coordinates\n",
    "    df[lat_col] = pd.to_numeric(df[lat_col], errors=\"coerce\")\n",
    "    df[lon_col] = pd.to_numeric(df[lon_col], errors=\"coerce\")\n",
    "\n",
    "    # Drop rows with missing coords\n",
    "    df = df.dropna(subset=[lat_col, lon_col])\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        lat = row[lat_col]\n",
    "        lon = row[lon_col]\n",
    "\n",
    "        # Build properties (everything except lat/lon)\n",
    "        properties = {\n",
    "            col: (None if pd.isna(row[col]) else row[col])\n",
    "            for col in df.columns\n",
    "            if col not in [lat_col, lon_col]\n",
    "        }\n",
    "\n",
    "        feature = {\n",
    "            \"type\": \"Feature\",\n",
    "            \"geometry\": {\n",
    "                \"type\": \"Point\",\n",
    "                \"coordinates\": [float(lon), float(lat)]\n",
    "            },\n",
    "            \"properties\": properties\n",
    "        }\n",
    "\n",
    "        if id_col and id_col in row:\n",
    "            feature[\"id\"] = row[id_col]\n",
    "\n",
    "        features.append(feature)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"FeatureCollection\",\n",
    "        \"features\": features\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3596ea62",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_data = dataframe_to_geojson(\n",
    "    stations,\n",
    "    lat_col=\"latitude\",\n",
    "    lon_col=\"longitude\"\n",
    ")\n",
    "\n",
    "with open(\"output.geojson\", \"w\") as f:\n",
    "    json.dump(geojson_data, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b1e65b",
   "metadata": {},
   "source": [
    "Converting weather crime data to a geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1bca502",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_with_weather = pd.read_csv(\"crime_with_weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "187db572",
   "metadata": {},
   "outputs": [],
   "source": [
    "geojson_data = dataframe_to_geojson(\n",
    "    crime_with_weather,\n",
    "    lat_col=\"LATITUDE_PUBLIC\",\n",
    "    lon_col=\"LONGITUDE_PUBLIC\"\n",
    ")\n",
    "\n",
    "with open(\"output.geojson\", \"w\") as f:\n",
    "    json.dump(geojson_data, f, indent=2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtsc-capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
